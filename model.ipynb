{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_val_score, TimeSeriesSplit\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "import gc\n",
    "\n",
    "from model.helper import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        output = pd.DataFrame()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(X[col])\n",
    "        else:\n",
    "            for colname,col in X.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NanInputter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, nan_value):\n",
    "        self.nan_value = nan_value\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.nan_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return np.log10(X).values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DayPeriodic(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        hour = pd.to_datetime(X, unit='s').dt.hour\n",
    "        sin_hour = np.sin(2*np.pi*hour/24)\n",
    "        cos_hour = np.cos(2*np.pi*hour/24)\n",
    "        \n",
    "        return pd.concat([sin_hour, cos_hour], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DayHour(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        hour = pd.to_datetime(X, unit='s').dt.hour.values\n",
    "        return hour.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivlis/.conda/envs/jlab/lib/python3.7/site-packages/pyarrow/pandas_compat.py:708: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels = getattr(columns, 'labels', None) or [\n",
      "/home/ivlis/.conda/envs/jlab/lib/python3.7/site-packages/pyarrow/pandas_compat.py:735: FutureWarning: the 'labels' keyword is deprecated, use 'codes' instead\n",
      "  return pd.MultiIndex(levels=new_levels, labels=labels, names=columns.names)\n",
      "/home/ivlis/.conda/envs/jlab/lib/python3.7/site-packages/pyarrow/pandas_compat.py:752: FutureWarning: .labels was deprecated in version 0.24.0. Use .codes instead.\n",
      "  labels, = index.labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2666"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pq.read_table('data/train.parquet').to_pandas()\n",
    "test = pq.read_table('data/test.parquet').to_pandas()\n",
    "\n",
    "# train = train[]\n",
    "# test = test[:20000]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_black_list = ['TransactionID', 'isFraud']\n",
    "\n",
    "features = train.columns\n",
    "types = train.dtypes\n",
    "types = types[~features.isin(features_black_list)]\n",
    "features = features[~features.isin(features_black_list)]\n",
    "\n",
    "\n",
    "categorical = features[types =='object']\n",
    "numerical = features[~(types =='object')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This features will be processed in a special way and will not be included in automated inputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_features = ['TransactionAmt', 'TransactionDT']\n",
    "categorical = categorical[~categorical.isin(special_features)]\n",
    "numerical = numerical[~numerical.isin(special_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrongly_numerical = pd.Index(['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2'])\n",
    "# numerical = numerical[~numerical.isin(wrongly_numerical)]\n",
    "# categorical = categorical.union(wrongly_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1',\n",
       "       'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'id_12', 'id_15',\n",
       "       'id_16', 'id_23', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_33',\n",
       "       'id_34', 'id_35', 'id_36', 'id_37', 'id_38', 'DeviceType',\n",
       "       'DeviceInfo'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['card1', 'card2', 'card3', 'card5', 'addr1', 'addr2', 'dist1', 'dist2',\n",
       "       'C1', 'C2',\n",
       "       ...\n",
       "       'id_17', 'id_18', 'id_19', 'id_20', 'id_21', 'id_22', 'id_24', 'id_25',\n",
       "       'id_26', 'id_32'],\n",
       "      dtype='object', length=399)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = FeatureUnion(\n",
    "    [\n",
    "        ('AmountLog', make_pipeline(ItemSelector('TransactionAmt'), Log())),\n",
    "        ('DayPeriodic', make_pipeline(ItemSelector('TransactionDT'), DayPeriodic())),\n",
    "        ('CategoricalLabeling', make_pipeline(\n",
    "            ItemSelector(categorical), \n",
    "            NanInputter('None'),\n",
    "            MultiColumnLabelEncoder())),\n",
    "        ('NumericalInputter', make_pipeline(\n",
    "            ItemSelector(numerical),\n",
    "            NanInputter(-1000)\n",
    "            ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = make_pipeline(combined_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_params = {\n",
    "    'task': 'train',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': True,\n",
    "    'objective': 'binary',\n",
    "    'max_bin': 63,\n",
    "    'num_leaves': 255,\n",
    "    'learning_rate': 0.01,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = make_pipeline(preprocess, lgb.LGBMClassifier(**lgbm_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96546381, 0.96625123, 0.96392285, 0.94783588])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(estimator, train, train.isFraud, cv = TimeSeriesSplit(n_splits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-52c540985e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.96647137\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.96277983\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.96139974\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.93686287\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "array([0.96647137, 0.96277983, 0.96139974, 0.93686287])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pipeline',\n",
       "                 Pipeline(memory=None,\n",
       "                          steps=[('featureunion',\n",
       "                                  FeatureUnion(n_jobs=None,\n",
       "                                               transformer_list=[('AmountLog',\n",
       "                                                                  Pipeline(memory=None,\n",
       "                                                                           steps=[('itemselector',\n",
       "                                                                                   ItemSelector(key='TransactionAmt')),\n",
       "                                                                                  ('log',\n",
       "                                                                                   Log())],\n",
       "                                                                           verbose=False)),\n",
       "                                                                 ('DayPeriodic',\n",
       "                                                                  Pipeline(memory=None,\n",
       "                                                                           steps=[('itemselector',\n",
       "                                                                                   ItemSelector(key='TransactionDT')),\n",
       "                                                                                  ('day...\n",
       "                                colsample_bytree=1.0, importance_type='split',\n",
       "                                is_unbalance=True, learning_rate=0.01,\n",
       "                                max_bin=63, max_depth=-1, metric='auc',\n",
       "                                min_child_samples=20, min_child_weight=0.001,\n",
       "                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,\n",
       "                                num_leaves=255, objective='binary',\n",
       "                                random_state=None, reg_alpha=0.0,\n",
       "                                reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "                                subsample_for_bin=200000, subsample_freq=0,\n",
       "                                task='train'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(train, train.isFraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pq.read_table('data/sub.parquet').to_pandas()\n",
    "sample_submission['isFraud'] = estimator.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-jlab] *",
   "language": "python",
   "name": "conda-env-.conda-jlab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
